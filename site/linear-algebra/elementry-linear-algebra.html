
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Glossary of Linear Algebra Concepts | Elijah's Notes</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="Provides an overview of basic linear algebra concepts and techniques, including Gaussian elimination, systems of equations, row operations, matrix-vector multiplication, and matrix-matrix multiplication, providing efficient methods for solving systems of equations and transforming matrices. It also touches on the relationships between these concepts, such as span and linear transformations. The document distinguishes between inefficient and efficient approaches to solving systems of equations.">
    <meta name="author" content="Elijah Melton">
    <meta name="robots" content="index, follow">
    <meta name="generator" content="Custom Static Site Generator">
    <link rel="canonical" href="https://notes.elimelt.com/linear-algebra/elementry-linear-algebra.html">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Glossary of Linear Algebra Concepts">
    <meta property="og:description" content="Provides an overview of basic linear algebra concepts and techniques, including Gaussian elimination, systems of equations, row operations, matrix-vector multiplication, and matrix-matrix multiplication, providing efficient methods for solving systems of equations and transforming matrices. It also touches on the relationships between these concepts, such as span and linear transformations. The document distinguishes between inefficient and efficient approaches to solving systems of equations.">
    <meta property="og:url" content="https://notes.elimelt.com/linear-algebra/elementry-linear-algebra.html">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Glossary of Linear Algebra Concepts">
    <meta name="twitter:description" content="Provides an overview of basic linear algebra concepts and techniques, including Gaussian elimination, systems of equations, row operations, matrix-vector multiplication, and matrix-matrix multiplication, providing efficient methods for solving systems of equations and transforming matrices. It also touches on the relationships between these concepts, such as span and linear transformations. The document distinguishes between inefficient and efficient approaches to solving systems of equations.">

    <meta name="keywords" content="gaussian elimination,matrix-vector multiplication,linear transformations,matrix-matrix multiplication">

    <!-- Schema.org JSON-LD -->
    <script type="application/ld+json">
    {"@context": "https://schema.org", "@type": "Article", "headline": "Glossary of Linear Algebra Concepts", "dateModified": "2025-02-12T12:52:07.373507", "description": "Provides an overview of basic linear algebra concepts and techniques, including Gaussian elimination, systems of equations, row operations, matrix-vector multiplication, and matrix-matrix multiplication, providing efficient methods for solving systems of equations and transforming matrices. It also touches on the relationships between these concepts, such as span and linear transformations. The document distinguishes between inefficient and efficient approaches to solving systems of equations.", "articleSection": "Linear Algebra", "keywords": "gaussian elimination,matrix-vector multiplication,linear transformations,matrix-matrix multiplication"}
    </script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/verilog.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/java.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/cpp.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/c.min.js"></script>
    <link rel="stylesheet" href=/css/styles.css>

    <!-- Configure KaTeX auto-render -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "\[", right: "\]", display: true},
                    {left: "$", right: "$", display: false},
                ],
                preProcess: (math) => {
                    console.log("Pre-processing: " + math);
                    math = math.split("\n").map((line) => {
                        if (line.endsWith("\\")) {
                            return line + "\\";
                        }
                        return line;
                    }).join("\n");
                    return math;
                },
                throwOnError: false
            });
        });
    </script>
    <!-- Configure Highlight.js -->
    <script>hljs.highlightAll();</script>
</head>
<body>
    <header>
        <nav role="navigation" aria-label="Main navigation">
            <a href="/index.html">Home</a>
<a href="/categories/index.html">Categories</a>
<a href="/tags/index.html">Tags</a>
        </nav>
        <div class="breadcrumbs" role="navigation" aria-label="Breadcrumb">
            <a href="/index.html">Home</a> » <a href="/categories/linear%20algebra.html">Linear Algebra</a> » Glossary of Linear Algebra Concepts
        </div>
    </header>
    <main role="main">
        <article>
            <h1>Glossary of Linear Algebra Concepts</h1>
            <div class="meta">
                <time datetime="2025-02-12T12:52:07.373507">
                    Last modified: 2025-02-12
                </time>
                <span>Category: <a href="/categories/linear%20algebra.html">Linear Algebra</a></span>
                <span><a id="parent-link" href="index.html">..</a></span>
            </div>
            <div class=markdown-content content>
                <h1 id="elementary-linear-algebra">Elementary Linear Algebra</h1>
<h2 id="systems-of-equations">Systems of Equations</h2>
<p>Systems of equations are both fundamental and important to actually understanding linear algebra. With that being said, the two primary introductory courses at the University of Washington, Math 208 and (to a much lesser extent) Applied Math 352, spend a significant amount of time on methods for <em>solving</em> systems of equations, something that I have almost no interest in. For the sake of completeness, I will briefly touch on notation and algorithms, but will try to both confine it to this document, and to focus on takeaways that become more useful later on.</p>
<h3 id="notation">Notation</h3>
<p>$$
\begin{aligned}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n &amp;= b_1 \
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n &amp;= b_2 \
&amp;\vdots \
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n &amp;= b_m
\end{aligned}
$$</p>
<p>Or equivalently, in matrix form $Ax = b$.</p>
<p>$$
\begin{aligned}
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}
\end{bmatrix}
\begin{bmatrix}
x_1 \
x_2 \
\vdots \
x_n
\end{bmatrix}
&amp;=
\begin{bmatrix}
b_1 \
b_2 \
\vdots \
b_m
\end{bmatrix}
\end{aligned}
$$</p>
<h3 id="gaussian-elimination">Gaussian Elimination</h3>
<p>Perform any of the following <strong>elementary row operations</strong> to the augmented matrix $\lbrack  A|b  \rbrack$:</p>
<ul>
<li>Swap two rows</li>
<li>Multiply a row by a nonzero scalar</li>
<li>Add a multiple of one row to another</li>
</ul>
<p>The aim of the algorithm is to get the matrix into either <strong>row echelon form</strong> or <strong>reduced row echelon form</strong>. The former is a matrix where the first nonzero element in each row is 1, and the first nonzero element in each row is to the right of the first nonzero element in the row above it. The latter is a matrix where the first nonzero element in each row is 1, and the first nonzero element in each row is the only nonzero element in its column. For example, below $A$ is in row echelon form, and $B$ is in reduced row echelon form.</p>
<p>$$
\begin{aligned}
A &amp;=
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} \
0 &amp; a_{22} &amp; a_{23} &amp; a_{24} \
0 &amp; 0 &amp; a_{33} &amp; a_{34} \
0 &amp; 0 &amp; 0 &amp; a_{44}
\end{bmatrix}
\
B &amp;=
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \
0 &amp; 1 &amp; 0 &amp; 0 \
0 &amp; 0 &amp; 1 &amp; 0 \
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\end{aligned}
$$</p>
<p>As you perform row operations, you also act on $b$ to keep the system equivalent. Once you have the matrix in row echelon form, you can solve the system by back substitution, or by continuing to row reduce to reduced row echelon form, where the solution is immediately apparent.</p>
<h3 id="takeaways">Takeaways</h3>
<h4 id="row-operations">Row Operations</h4>
<p>Solving systems of equations is pretty boring, but the emergent structure of a system on the verge of being solved cements a few important ideas:</p>
<ul>
<li><strong>Row operations</strong> need to <em>somehow</em> be legal, in particular reversible and preservative of the solution set. This is a good example of a <strong>group</strong> in action.</li>
<li>The result of running Gaussian elimination is a <strong>basis</strong> for the solution set. This gives the <strong>span</strong> of the solution set, and the <strong>rank</strong> of the matrix.</li>
<li>Additional rows of zero left in the matrix after row reduction indicate <strong>redundancy</strong>, or in other words, <strong>linear dependence</strong>.</li>
</ul>
<h4 id="span">Span</h4>
<p>The span of a set of vectors is the set of all possible linear combinations of those vectors. The span of a set of vectors is a <strong>subspace</strong> of the vector space. The span of a set of vectors is the <strong>null space</strong> of the matrix whose columns are those vectors.</p>
<p>$$
\begin{aligned}
\text{span}\left{ \begin{bmatrix} 1 \ 0 \end{bmatrix}, \begin{bmatrix} 0 \ 1 \end{bmatrix} \right} &amp;= \mathbb{R}^2 \
\text{span}\left{ \begin{bmatrix} 1 \ 0 \end{bmatrix}, \begin{bmatrix} 0 \ 1 \end{bmatrix}, \begin{bmatrix} 1 \ 1 \end{bmatrix} \right} &amp;= \mathbb{R}^2 \
\text{span}\left{ \begin{bmatrix} 1 \ 0 \end{bmatrix}, \begin{bmatrix} 0 \ 1 \end{bmatrix}, \begin{bmatrix} 1 \ 1 \end{bmatrix} \right} &amp;= \text{span}\left{ \begin{bmatrix} 1 \ 0 \end{bmatrix}, \begin{bmatrix} 0 \ 1 \end{bmatrix} \right}
\end{aligned}
$$</p>
<p>For a set of $n$ vectors in $\mathbb{R}^n$ to span $\mathbb{R}^n$, the vectors must be linearly independent. This is a necessary and sufficient condition for a set of vectors to be a <strong>basis</strong> for $\mathbb{R}^n$. You can perform additional reasoning to determine the rules for spanning sets, and implications on linear independence. For instance, a set of less than $n$ vectors in $\mathbb{R}^n$ cannot span $\mathbb{R}^n$, and a set of more than $n$ vectors in $\mathbb{R}^n$ must be linearly dependent.</p>
<h4 id="linear-transformations">Linear Transformations</h4>
<p>For a function to be linear, it must satisfy two properties:</p>
<ul>
<li><strong>Additivity</strong>: $f(x + y) = f(x) + f(y)$</li>
<li><strong>Homogeneity</strong>: $f(cx) = cf(x)$</li>
</ul>
<p>A linear transformation is a function $T: \mathbb{R}^n \to \mathbb{R}^m$ that satisfies these properties. The <strong>kernel</strong> of a linear transformation is the set of vectors that are mapped to the zero vector, e.g. $T(x) = 0$, or $Ax = 0$ for a matrix $A$ that represents the transformation. The kernel is a subspace of the domain. The <strong>range</strong> of a linear transformation is the set of all possible outputs, and is a subspace of the codomain.</p>
<p>$$
\begin{aligned}
T: \mathbb{R}^2 &amp;\to \mathbb{R}^2 \
T\left( \begin{bmatrix} x \ y \end{bmatrix} \right) &amp;= \begin{bmatrix} x \ 0 \end{bmatrix}
\end{aligned}
$$</p>
<p>$$
\begin{aligned}
\text{ker}(T) &amp;= \text{span}\left{ \begin{bmatrix} 0 \ 1 \end{bmatrix} \right} \
\text{range}(T) &amp;= \text{span}\left{ \begin{bmatrix} 1 \ 0 \end{bmatrix} \right}
\end{aligned}
$$</p>
<h4 id="matrix-vector-multiplication">Matrix-Vector Multiplication</h4>
<p>$$
\begin{aligned}
A\begin{bmatrix} x \ y \end{bmatrix} &amp;= x\begin{bmatrix} a_{11} \ a_{21} \end{bmatrix} + y\begin{bmatrix} a_{12} \ a_{22} \end{bmatrix} \
&amp;= \begin{bmatrix} a_{11}x + a_{12}y \ a_{21}x + a_{22}y \end{bmatrix}
\end{aligned}
$$</p>
<p>Matrix-vector multiplication is a linear transformation. The columns of the matrix are the images of the basis vectors, and the result is the image of the input vector. The kernel of the transformation is the null space of the matrix, and the range is the column space of the matrix.</p>
<p>Visually, you can picture transforming the basis vectors/unit square of the domain into the basis vectors/unit square of the codomain. The matrix is the transformation matrix, and the columns are the images of the basis vectors. The result is the image of the input vector.</p>
<h4 id="matrix-matrix-multiplication">Matrix-Matrix Multiplication</h4>
<p>$$
\begin{aligned}
AB &amp;= A\begin{bmatrix} b_1 &amp; b_2 &amp; \cdots &amp; b_n \end{bmatrix} \
&amp;= \begin{bmatrix} Ab_1 &amp; Ab_2 &amp; \cdots &amp; Ab_n \end{bmatrix}
\end{aligned}
$$</p>
<p>The algorithm here is to multiply the matrix on the right by each column of the matrix on the left. The result is a matrix whose columns are the images of the columns of the matrix on the right. This is a linear transformation, and the kernel of the transformation is the null space of the matrix on the right, and the range is the column space of the matrix on the left.q</p>
<pre><code class="language-python">import numpy as np

# inefficient
def multiply_bad(A, B):
    C = np.zeros((A.shape[0], B.shape[1]))
    for i in range(A.shape[0]):
        for j in range(B.shape[1]):
            for k in range(A.shape[1]):
                C[i, j] += A[i, k] * B[k, j]
    return C

# efficient
def multiply_good(A, B):
    return np.dot(A, B)

M, N = 10000, 10000
A = np.random.rand(M, N)
B = np.random.rand(N, M)

%timeit multiply_bad(A, B)
%timeit multiply_good(A, B)
</code></pre>
<pre><code class="language-plaintext">
</code></pre>
<p>Matrix multiplication is fundamentally a costly operation, taking $O(n^3)$ time. That being said, libraries like numpy are heavily optimized and can perform matrix multiplication orders of magnitude faster than naive implementations using vectorized operations. In practice you should <strong>never</strong> write your own matrix multiplication.</p>
            </div>
            <div class="tags">
                Tags:
                <a href="/tags/gaussian%20elimination.html">gaussian elimination</a>
                <a href="/tags/linear%20transformations.html">linear transformations</a>
                <a href="/tags/matrix-matrix%20multiplication.html">matrix-matrix multiplication</a>
                <a href="/tags/matrix-vector%20multiplication.html">matrix-vector multiplication</a>
            </div>
        </article>
    </main>
    <footer role="contentinfo">
        <p>2025, authored by Elijah Melton.</p>
    </footer>
</body>
</html>
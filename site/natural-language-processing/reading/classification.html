
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Classification with Multinomial Naive Bayes | Elijah's Notes</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="Overview of classification with Multinomial Naive Bayes, including the Naive Bayes assumption, training, and evaluation.">
    <meta name="author" content="Elijah Melton">
    <meta name="robots" content="index, follow">
    <meta name="generator" content="Custom Static Site Generator">
    <link rel="canonical" href="https://notes.elimelt.com/natural-language-processing/reading/classification.html">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Classification with Multinomial Naive Bayes">
    <meta property="og:description" content="Overview of classification with Multinomial Naive Bayes, including the Naive Bayes assumption, training, and evaluation.">
    <meta property="og:url" content="https://notes.elimelt.com/natural-language-processing/reading/classification.html">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Classification with Multinomial Naive Bayes">
    <meta name="twitter:description" content="Overview of classification with Multinomial Naive Bayes, including the Naive Bayes assumption, training, and evaluation.">

    <meta name="keywords" content="classification,naive bayes,multinomial naive bayes,text classification,bag of words,laplace smoothing">

    <!-- Schema.org JSON-LD -->
    <script type="application/ld+json">
    {"@context": "https://schema.org", "@type": "Article", "headline": "Classification with Multinomial Naive Bayes", "dateModified": "2025-02-12T15:23:20.176602", "description": "Overview of classification with Multinomial Naive Bayes, including the Naive Bayes assumption, training, and evaluation.", "articleSection": "Natural Language Processing", "keywords": "classification,naive bayes,multinomial naive bayes,text classification,bag of words,laplace smoothing"}
    </script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js"></script>

    <!-- Configure KaTeX auto-render -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "\[", right: "\]", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\(", right: "\)", display: false}
                ],
                preProcess: (math) => {
                    console.log("Pre-processing: " + math);
                    math = math.split("\n").map((line) => {
                        if (line.endsWith("\\")) {
                            return line + "\\";
                        }
                        return line;
                    }).join("\n");
                    console.log("Post-processing: " + math);
                    return math;
                },
                throwOnError: false
            });
        });
    </script>

<style>
    :root {
        --text-color: #1a1a1a;
        --background-color: #ffffff;
        --accent-color: #2563eb;
        --border-color: #e5e7eb;
        --nav-background: rgba(255, 255, 255, 0.95);
    }

    @media (prefers-color-scheme: dark) {
        :root {
            --text-color: #f3f4f6;
            --background-color: #1a1a1a;
            --accent-color: #60a5fa;
            --border-color: #374151;
            --nav-background: rgba(26, 26, 26, 0.95);
        }
    }

    body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
        line-height: 1.6;
        max-width: 50rem;
        margin: 0 auto;
        padding: 2rem;
        color: var(--text-color);
        background: var(--background-color);
    }

    nav {
        position: sticky;
        top: 0;
        background: var(--nav-background);
        backdrop-filter: blur(10px);
        border-bottom: 1px solid var(--border-color);
        padding: 1rem 0;
        margin-bottom: 2rem;
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
        z-index: 1000;
    }

    nav a {
        color: var(--accent-color);
        text-decoration: none;
        padding: 0.5rem 1rem;
        border-radius: 4px;
        transition: background-color 0.2s;
    }

    nav a:hover {
        background-color: var(--border-color);
    }

    .breadcrumbs {
        margin-bottom: 2rem;
        color: var(--text-color);
        opacity: 0.8;
    }

    .breadcrumbs a {
        color: var(--accent-color);
        text-decoration: none;
    }

    .content {
        margin-top: 2rem;
    }

    h1, h2, h3, h4, h5, h6 {
        margin-top: 2rem;
        margin-bottom: 1rem;
        line-height: 1.3;
    }

    code {
        background: var(--border-color);
        padding: 0.2rem 0.4rem;
        border-radius: 3px;
        font-size: 0.9em;
        font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
    }

    pre {
        background: var(--border-color);
        padding: 1rem;
        border-radius: 4px;
        overflow-x: auto;
        margin: 1.5rem 0;
    }

    pre code {
        background: none;
        padding: 0;
        border-radius: 0;
    }

    img {
        max-width: 100%;
        height: auto;
        border-radius: 4px;
        margin: 1.5rem 0;
    }

    .meta {
        color: var(--text-color);
        opacity: 0.8;
        font-size: 0.9em;
        margin-bottom: 2rem;
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
    }

    .tags {
        margin-top: 2rem;
        padding-top: 1rem;
        border-top: 1px solid var(--border-color);
    }

    .tags a {
        display: inline-block;
        background: var(--border-color);
        color: var(--text-color);
        padding: 0.2rem 0.6rem;
        border-radius: 3px;
        text-decoration: none;
        font-size: 0.9em;
        margin-right: 0.5rem;
        margin-bottom: 0.5rem;
    }

    .tags a:hover {
        background: var(--accent-color);
        color: white;
    }

    a {
        color: #3391ff;
    }

    table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
    }

    th, td {
        padding: 0.75rem;
        border: 1px solid var(--border-color);
    }

    th {
        background: var(--border-color);
    }

    .md-content table td, .md-content table th {
        background: black;
    }

    blockquote {
        margin: 1.5rem 0;
        padding-left: 1rem;
        border-left: 4px solid var(--accent-color);
        color: var(--text-color);
        opacity: 0.8;
    }

    .katex-display {
        overflow: auto hidden;
        padding: 1em 0;
        margin: 0.5em 0;
    }

    .katex-display > .katex {
        white-space: normal;
    }

    .katex {
        font-size: 1.1em;
        display: inline;
        line-height: 1.2;
    }

    .katex-html {
        display: inline-block;
        vertical-align: middle;
    }

    .katex .strut {
        display: none;
    }

    .katex-display .katex {
        display: block;
        text-align: center;
    }

    .katex-display > .katex > .katex-html {
        display: block;
        max-width: 100%;
        overflow-x: auto;
        padding: 0.5em 0;
        min-height: 40px;
    }
</style></head>
<body>
    <header>
        <nav role="navigation" aria-label="Main navigation">
            <a href="/index.html">Home</a>
<a href="/categories/index.html">Categories</a>
<a href="/tags/index.html">Tags</a>
        </nav>
        <div class="breadcrumbs" role="navigation" aria-label="Breadcrumb">
            <a href="/index.html">Home</a> » <a href="/categories/natural%20language%20processing.html">Natural Language Processing</a> » Classification with Multinomial Naive Bayes
        </div>
    </header>
    <main role="main">
        <article>
            <h1>Classification with Multinomial Naive Bayes</h1>
            <div class="meta">
                <time datetime="2025-02-12T15:23:20.176602">
                    Last modified: 2025-02-12
                </time>
                <span>Category: <a href="/categories/natural%20language%20processing.html">Natural Language Processing</a></span>
            </div>
            <div class="content">
                <h1 id="classification">Classification</h1>
<p>Take an input $x$ and a fixed set of output classes $Y = {y_1, y_2, \ldots, y_M}$ and return a predicted class $y \in Y$.</p>
<p>Text classification sometimes uses $c$ for class instead of $y$ as output, and $d$ for document instead of $x$ as input.</p>
<p>In the supervised situation we have a training set of $N$ documents that have each been hand labeled with a class: ${(d_1, c_1),....,(d_N, c_N)}$. Our goal is to learn a classifier that is capable of mapping from a new document $d$ to its correct class $c \in C$, where $C$ is some set of useful document classes.</p>
<h2 id="multinomial-naive-bayes">Multinomial Naive Bayes</h2>
<p>Represent text as <strong>bag of words</strong>. For a document $d$ out of all all classes $c \in C$, outputs $\hat{c}$ that maximizes $P(c|d)$.</p>
<p>$$
\begin{aligned}
\hat{c} &amp;= \arg \max_{c \in C} P(c|d) \
  &amp;= \arg \max_{c \in C} \frac{P(d|c)P(c)}{P(d)}
\end{aligned}
$$</p>
<p>Where $P(d | c)$ is the likelihood, and $P(c)$ is the prior. Or with features $f_1, f_2, \ldots, f_n$:</p>
<p>$$
\hat{c} = \arg \max_{c \in C} P(f_1, f_2, \ldots, f_n | c)P(c)
$$</p>
<h3 id="naive-bayes-assumption">Naive Bayes Assumption</h3>
<p>$$
P(f_1, f_2, \ldots, f_n | c) = \prod_{i=1}^n P(f_i | c)
$$</p>
<p>$$
\begin{aligned}
C_{\text{NB}} &amp;= \arg \max_{c \in C} P(c) \prod_{i=1}^n P(w_i | c) \
&amp;= \arg \max_{c \in C} \log P(c) + \sum_{i=1}^n \log P(w_i | c)
\end{aligned}
$$</p>
<p>$$
A = B \
\Rightarrow \log A = \log B
$$</p>
<h3 id="training">Training</h3>
<p>Estimate $P(c)$: the prior probability of each class.</p>
<p>$$
\hat{P}(w_i | c) = \frac{count(w_i, c) + 1}{\sum_{w \in V} count(w, c) + |V|}
$$</p>
<p>Or with Laplace smoothing:</p>
<p>$$
\hat{P}(w_i | c) = \frac{count(w_i, c) + 1}{\sum_{w \in V} count(w, c) + |V|}
$$</p>
<pre><code>function TRAIN_NAIVE_BAYES(D, C) returns V, log_P(c), log_P(w|c)
  for each class c ∈ C do
    Ndoc = number of documents in D
    Nc = number of documents from D in class c
    logprior[c] = log(Nc / Ndoc)
    V = vocab of D
    bigdoc[c] = concat(d ∈ D where d.class = c)
    for each word w ∈ V do
      count[w, c] = number of times w appears in bigdoc[c]
      loglikelihood[w, c] = log [(count[w, c] + 1) / (sum_{w' ∈ V} count[w', c] + |V|)]

  return logprior, loglikelihood, V

function TEST_NAIVE_BAYES(testdoc, logprior, loglikelihood, C, V) returns best_c
  for each class c ∈ C do
    sum[c] = logprior[c]
    for each position i in testdoc do
      word = testdoc[i]
      if word ∈ V then
        sum[c] = sum[c] + loglikelihood[word, c]

  return argmax_c sum[c]
</code></pre>
<h3 id="evaluation">Evaluation</h3>
<p>Use a confusion matrix, precision, recall, and F1 score.</p>
            </div>
            <div class="tags">
                Tags:
                <a href="/tags/bag%20of%20words.html">bag of words</a>
                <a href="/tags/classification.html">classification</a>
                <a href="/tags/laplace%20smoothing.html">laplace smoothing</a>
                <a href="/tags/multinomial%20naive%20bayes.html">multinomial naive bayes</a>
                <a href="/tags/naive%20bayes.html">naive bayes</a>
                <a href="/tags/text%20classification.html">text classification</a>
            </div>
        </article>
    </main>
    <footer role="contentinfo">
        <p>2025, authored by Elijah Melton.</p>
    </footer>
</body>
</html>
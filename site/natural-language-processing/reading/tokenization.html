
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tokenization, Segmentation, and Edit Distance | Elijah's Notes</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="Overview of tokenization techniques in Natural Language Processing (NLP), including Unix tools, regex, Byte-Pair Encoding (BPE), and edit distance.">
    <meta name="author" content="Elijah Melton">
    <meta name="robots" content="index, follow">
    <meta name="generator" content="Custom Static Site Generator">
    <link rel="canonical" href="https://notes.elimelt.com/natural-language-processing/reading/tokenization.html">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Tokenization, Segmentation, and Edit Distance">
    <meta property="og:description" content="Overview of tokenization techniques in Natural Language Processing (NLP), including Unix tools, regex, Byte-Pair Encoding (BPE), and edit distance.">
    <meta property="og:url" content="https://notes.elimelt.com/natural-language-processing/reading/tokenization.html">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Tokenization, Segmentation, and Edit Distance">
    <meta name="twitter:description" content="Overview of tokenization techniques in Natural Language Processing (NLP), including Unix tools, regex, Byte-Pair Encoding (BPE), and edit distance.">

    <meta name="keywords" content="tokenization,segmentation,edit distance,bpe,nltk,tr,regex,byte-pair encoding">

    <!-- Schema.org JSON-LD -->
    <script type="application/ld+json">
    {"@context": "https://schema.org", "@type": "Article", "headline": "Tokenization, Segmentation, and Edit Distance", "dateModified": "2025-02-12T00:59:15.625957", "description": "Overview of tokenization techniques in Natural Language Processing (NLP), including Unix tools, regex, Byte-Pair Encoding (BPE), and edit distance.", "articleSection": "Natural Language Processing", "keywords": "tokenization,segmentation,edit distance,bpe,nltk,tr,regex,byte-pair encoding"}
    </script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js"></script>

    <!-- Configure KaTeX auto-render -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "\\[", right: "\\]", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\\(", right: "\\)", display: false}
                ],
                ignoredTags: ["script", "noscript", "style", "textarea", "em"],
                throwOnError: false
            });
        });
    </script>

<style>
    :root {
        --text-color: #1a1a1a;
        --background-color: #ffffff;
        --accent-color: #2563eb;
        --border-color: #e5e7eb;
        --nav-background: rgba(255, 255, 255, 0.95);
    }

    @media (prefers-color-scheme: dark) {
        :root {
            --text-color: #f3f4f6;
            --background-color: #1a1a1a;
            --accent-color: #60a5fa;
            --border-color: #374151;
            --nav-background: rgba(26, 26, 26, 0.95);
        }
    }

    body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
        line-height: 1.6;
        max-width: 50rem;
        margin: 0 auto;
        padding: 2rem;
        color: var(--text-color);
        background: var(--background-color);
    }

    nav {
        position: sticky;
        top: 0;
        background: var(--nav-background);
        backdrop-filter: blur(10px);
        border-bottom: 1px solid var(--border-color);
        padding: 1rem 0;
        margin-bottom: 2rem;
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
        z-index: 1000;
    }

    nav a {
        color: var(--accent-color);
        text-decoration: none;
        padding: 0.5rem 1rem;
        border-radius: 4px;
        transition: background-color 0.2s;
    }

    nav a:hover {
        background-color: var(--border-color);
    }

    .breadcrumbs {
        margin-bottom: 2rem;
        color: var(--text-color);
        opacity: 0.8;
    }

    .breadcrumbs a {
        color: var(--accent-color);
        text-decoration: none;
    }

    .content {
        margin-top: 2rem;
    }

    h1, h2, h3, h4, h5, h6 {
        margin-top: 2rem;
        margin-bottom: 1rem;
        line-height: 1.3;
    }

    code {
        background: var(--border-color);
        padding: 0.2rem 0.4rem;
        border-radius: 3px;
        font-size: 0.9em;
        font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
    }

    pre {
        background: var(--border-color);
        padding: 1rem;
        border-radius: 4px;
        overflow-x: auto;
        margin: 1.5rem 0;
    }

    pre code {
        background: none;
        padding: 0;
        border-radius: 0;
    }

    img {
        max-width: 100%;
        height: auto;
        border-radius: 4px;
        margin: 1.5rem 0;
    }

    .meta {
        color: var(--text-color);
        opacity: 0.8;
        font-size: 0.9em;
        margin-bottom: 2rem;
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
    }

    .tags {
        margin-top: 2rem;
        padding-top: 1rem;
        border-top: 1px solid var(--border-color);
    }

    .tags a {
        display: inline-block;
        background: var(--border-color);
        color: var(--text-color);
        padding: 0.2rem 0.6rem;
        border-radius: 3px;
        text-decoration: none;
        font-size: 0.9em;
        margin-right: 0.5rem;
        margin-bottom: 0.5rem;
    }

    .tags a:hover {
        background: var(--accent-color);
        color: white;
    }

    a {
        color: #3391ff;
    }

    table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
    }

    th, td {
        padding: 0.75rem;
        border: 1px solid var(--border-color);
    }

    th {
        background: var(--border-color);
    }

    .md-content table td, .md-content table th {
        background: black;
    }

    blockquote {
        margin: 1.5rem 0;
        padding-left: 1rem;
        border-left: 4px solid var(--accent-color);
        color: var(--text-color);
        opacity: 0.8;
    }

    .katex-display {
        overflow: auto hidden;
        padding: 1em 0;
        margin: 0.5em 0;
    }

    .katex-display > .katex {
        white-space: normal;
    }

    .katex {
        font-size: 1.1em;
        display: inline;
        line-height: 1.2;
    }

    .katex-html {
        display: inline-block;
        vertical-align: middle;
    }

    .katex .strut {
        display: none;
    }

    .katex-display .katex {
        display: block;
        text-align: center;
    }

    .katex-display > .katex > .katex-html {
        display: block;
        max-width: 100%;
        overflow-x: auto;
        padding: 0.5em 0;
        min-height: 40px;
    }
</style></head>
<body>
    <header>
        <nav role="navigation" aria-label="Main navigation">
            <a href="/index.html">Home</a>
<a href="/categories/index.html">Categories</a>
<a href="/tags/index.html">Tags</a>
        </nav>
        <div class="breadcrumbs" role="navigation" aria-label="Breadcrumb">
            <a href="/index.html">Home</a> » <a href="/categories/natural%20language%20processing.html">Natural Language Processing</a> » Tokenization, Segmentation, and Edit Distance
        </div>
    </header>
    <main role="main">
        <article>
            <h1>Tokenization, Segmentation, and Edit Distance</h1>
            <div class="meta">
                <time datetime="2025-02-12T00:59:15.625957">
                    Last modified: 2025-02-12
                </time>
                <span>Category: <a href="/categories/natural%20language%20processing.html">Natural Language Processing</a></span>
            </div>
            <div class="content">
                <h1 id="tokenization">Tokenization</h1>
<h2 id="old-school-unix">Old-School Unix</h2>
<pre><code class="language-bash"># output all words in a file, one per line
tr -sc 'A-Za-z' '\n' &lt; input.txt

# count the words in a file
tr -sc ’A-Za-z’ ’\n’ &lt; input.txt | sort | uniq -c

# count the words in a file, case-insensitive
tr -sc 'A-Za-z' '\n' &lt; input.txt | tr A-Z a-z | sort | uniq -c

# most frequent words
tr -sc 'A-Za-z' '\n' &lt; input.txt | tr A-Z a-z | sort | uniq -c | sort -n -r
</code></pre>
<h2 id="top-down-regex-tokenization">Top-Down Regex Tokenization</h2>
<pre><code class="language-python">import nltk

pattern = r'''(?x)     # set flag to allow verbose regexps
  (?:[A-Z]\.)+         # abbreviations, e.g. U.S.A.
| \w+(?:-\w+)*         # words with optional internal hyphens
| \$?\d+(?:\.\d+)?%?   # currency and percentages, e.g. $12.40, 82%
| \.\.\.               # ellipsis
| [.,;&quot;'?():-_`]       # these are separate tokens
'''

text = &quot;This is a sentence.  This is another sentence.&quot;
nltk.regexp_tokenize(text, pattern)
</code></pre>
<h2 id="bottom-up-tokenization-with-byte-pair-encoding-bpe">Bottom-Up Tokenization with Byte-Pair Encoding (BPE)</h2>
<p>BPE is a simple algorithm that learns tokens from a corpus by iteratively merging the most frequent pair of characters.</p>
<pre><code class="language-python">def get_freq(vocab: Dict[str, int]) -&gt; Dict[Tuple[str, str], int]:
    pairs = defaultdict(int)
    for word, freq in vocab.items():
        symbols = word.split()
        for i in range(len(symbols)-1):
            pairs[symbols[i], symbols[i+1]] += freq
    return pairs
</code></pre>
<pre><code class="language-python">def merge_vocab(pair: Tuple[str, str], vocab: Dict[str, int]) -&gt; Dict[str, int]:
    bigram = ' '.join(pair)
    replacement = ''.join(pair)
    new_vocab = {}

    for word, freq in vocab.items():
        new_word = word.replace(bigram, replacement)
        new_vocab[new_word] = freq

    return new_vocab
</code></pre>
<pre><code class="language-python">def bpe(C: List[str], k: int) -&gt; List[Tuple[str, str]]:
    vocab = defaultdict(int)
    for word in C:
        spaced = ' '.join(word)
        vocab[spaced] += 1

    merges = []

    for i in range(k):
        pairs = get_freq(vocab)
        if not pairs:
            break

        best_pair = max(pairs.items(), key=lambda x: x[1])[0]
        merges.append(best_pair)
        vocab = merge_vocab(best_pair, vocab)

    return merges
</code></pre>
<p>In my experience, it doesn't start working well until you use a lot of data and a lot of merges. I've only tried once though, using ~100MB of text and 10,000 merges.</p>
<pre><code class="language-python">corpus = [&quot;low&quot;, &quot;lowest&quot;, &quot;newer&quot;, &quot;wider&quot;, &quot;new&quot;, &quot;width&quot;]
num_merges = 10

merge_operations = bpe(corpus, num_merges)

print(&quot;Merge operations performed:&quot;)
for i, pair in enumerate(merge_operations, 1):
    print(f&quot;{i}. Merged '{pair[0]}' with '{pair[1]}'&quot;)
</code></pre>
<h2 id="segmentation-and-tokenization">Segmentation and Tokenization</h2>
<pre><code class="language-python">import nltk

sent_text = nltk.sent_tokenize(text)

for sentence in sent_text:
    tokenized_text = nltk.word_tokenize(sentence)
    tagged = nltk.pos_tag(tokenized_text)
    print(tagged)
</code></pre>
<h2 id="edit-distance">Edit Distance</h2>
<pre><code class="language-python">def min_edit_distance(w1, w2):
    n, m = len(w1), len(w2)
    dp = [[0] * (m + 1) for _ in range(n + 1)]

    for i in range(n + 1):
        dp[i][0] = i

    for j in range(m + 1):
        dp[0][j] = j

    for i in range(1, n + 1):
        for j in range(1, m + 1):
            if w1[i - 1] == w2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1]
            else:
                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])

    return dp[n][m]
</code></pre>
            </div>
            <div class="tags">
                Tags:
                <a href="/tags/bpe.html">bpe</a>
                <a href="/tags/byte-pair%20encoding.html">byte-pair encoding</a>
                <a href="/tags/edit%20distance.html">edit distance</a>
                <a href="/tags/nltk.html">nltk</a>
                <a href="/tags/regex.html">regex</a>
                <a href="/tags/segmentation.html">segmentation</a>
                <a href="/tags/tokenization.html">tokenization</a>
                <a href="/tags/tr.html">tr</a>
            </div>
        </article>
    </main>
    <footer role="contentinfo">
        <p>2025, authored by Elijah Melton.</p>
    </footer>
</body>
</html>